# -*- coding: utf-8 -*-
"""coco-fliter-converter.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16yL1Q1QFSJsxXjaIUyaFVsC7xeQu5xik

# Data Postprocessing (Convert Segmentation polygons into COCO format)
"""

import os
import cv2
import numpy as np
from imantics import Polygons, Mask
from skimage.measure import label
import json

# Directory containing images and labels
image_dir = '/content/drive/MyDrive/Final_Project/UAV-Fisheye/Fisheye'
label_dir = '/content/drive/MyDrive/Final_Project/UAV-Fisheye/Fisheye_Labels'

# Class labels and corresponding colors
classes = {
    (0,0,0): {"id": 0, "name": "background_clutter"},
    (128,0,0): {"id": 1, "name": "building"},
    (128,64,128): {"id": 2, "name": "road"},
    (0,128,0): {"id": 3, "name": "trees"},
    (128,128,0): {"id": 4, "name": "low_vegetation"},
    (64,0,128): {"id": 5, "name": "cars"},  # "moving_car" becomes "cars" with id 5
    (192,0,192): {"id": 6, "name": "cars"},  # "static_car" becomes "cars" with id 6
    (64,64,0): {"id": 7, "name": "people"},
}

# Initialize COCO format data
coco_format = {
    "info": {
        "description": "Your Dataset Description",
        "version": "1.0",
        "year": 2023,
        "contributor": "Your Name",
        "url": "Your Dataset URL",
        "date_created": "2023/08/02"
    },
    "images": [],
    "annotations": [],
    "licenses": [],
    "categories": [
        {"id": class_info["id"], "name": class_info["name"]}
        for class_info in classes.values()
    ]
}

# Process each image
for filename in os.listdir(image_dir):
    # Load the semantic segmentation map and original image
    image_path = os.path.join(image_dir, filename)
    label_path = os.path.join(label_dir, filename)
    image = cv2.imread(image_path)
    label_map = cv2.imread(label_path)
    label_map = cv2.cvtColor(label_map, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB

    if image is None or label_map is None:
        print(f"Could not load image or label map for file {filename}")
        continue

    # Add image information to COCO data
    image_id = len(coco_format["images"]) + 1
    coco_format["images"].append({
        "id": image_id,
        "width": image.shape[1],
        "height": image.shape[0],
        "file_name": filename,
        "license": 1,
        "date_captured": "2023/08/02"
    })

    # For each class
    for color, class_info in classes.items():
        # Create a binary mask for the current class
        binary_mask = np.all(label_map == color, axis=-1)

        # Check if binary_mask is not empty
        if np.any(binary_mask):
            # Separate instances in the binary mask
            labeled_mask = label(binary_mask)

            # For each instance
            for instance_id in np.unique(labeled_mask):
                if instance_id == 0:
                    continue  # Skip the background

                # Create a binary mask for the current instance
                instance_mask = (labeled_mask == instance_id)

                # Convert the instance mask into polygon coordinates
                polygons = Mask(instance_mask).polygons()

                # Store the polygon coordinates, class id, and other necessary information
                area = np.sum(instance_mask)
                contours, _ = cv2.findContours(instance_mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                x, y, w, h = cv2.boundingRect(contours[0])
                bbox = [x, y, w, h]
                annotation = {
                    "id": len(coco_format["annotations"]) + 1,
                    "image_id": image_id,
                    "category_id": class_info["id"],
                    "segmentation": polygons.segmentation,
                    "area": float(area),
                    "bbox": bbox,
                    "iscrowd": 0
                }
                coco_format["annotations"].append(annotation)

# Save COCO data to a file
with open('coco_annotations.json', 'w') as f:
    json.dump(coco_format, f)

# Load the COCO data
with open('coco_annotations.json', 'r') as f:
    coco_format = json.load(f)

# Define the important classes
important_classes = {"building", "trees", "cars", "people"}

# Filter the categories
coco_format["categories"] = [category for category in coco_format["categories"] if category["name"] in important_classes]

# Create a mapping from old category ids to new ids
old_to_new_ids = {category["id"]: i + 1 for i, category in enumerate(coco_format["categories"])}

# Update the category ids in the remaining categories
for category in coco_format["categories"]:
    category["id"] = old_to_new_ids[category["id"]]

# Filter the annotations and update the category ids
coco_format["annotations"] = [
    {
        **annotation,
        "category_id": old_to_new_ids[annotation["category_id"]],
    }
    for annotation in coco_format["annotations"]
    if annotation["category_id"] in old_to_new_ids
]

# Get the image ids of the remaining annotations
remaining_image_ids = set(annotation["image_id"] for annotation in coco_format["annotations"])

# Filter the images
coco_format["images"] = [image for image in coco_format["images"] if image["id"] in remaining_image_ids]

# Save the filtered COCO data to a new file
with open('filtered_coco_annotations.json', 'w') as f:
    json.dump(coco_format, f)